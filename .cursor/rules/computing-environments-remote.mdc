---
description: Rules for training and evaluating on remote Odra and Polonez Ubuntu servers (SSH access, environment variables, multi-GPU bugs).
alwaysApply: false
---

## Rules for Working with Remote Servers (Polonez & Odra)
- **NEVER copy source code or project files directly to remote servers** (no `scp` or `rsync` of code files).
- **ALWAYS use Git to sync code**: commit locally, then ask the user to `git pull` on the remote server, or offer to trigger it via SSH.
- **Downloading Data**: Use `scripts/sync_evaluation_reports.ps1` to easily synchronize evaluation reports from remote servers to the local `Cache/` folder. This is easier than running manual SSH/scp commands on Polonez.
- **Execution Rules**: 
  - **Do NOT** start training automatically on remote servers. Always ask the user for permission.
  - **DO** run concept analysis (`analysis/run_concept_analysis.py`) automatically on remote checkpoints, because it is quick (a few seconds) and gives immediate results to log.
- Do not create/modify files on remote servers directly. Ask before changing server configuration.

## SSH Access to Remote Servers
Aliases are defined in `~/.ssh/config`. Use them directly:
- `ssh polonez` (4x RTX 3090, port 2205, `/home/ksopyla/dev/MrCogito`)
- `ssh odra` (3x RTX 3090, port 2203, `/home/ksopyla/dev/MrCogito`)

## Remote Environments
- **Polonez**: Ubuntu 22.04, 4x RTX 3090 (24GB VRAM each, CUDA 8.6), AMD Threadripper 3970X 32-Core, 256GB RAM.
- **Odra**: Ubuntu 22.04, 3x RTX 3090 (24GB VRAM each), AMD Threadripper 1900X 8-Core, 96GB RAM.
- **Python Setup**: Python 3.12 via Poetry (`poetry run python ...`). HuggingFace cache: `/home/ksopyla/hf_home/`.
- **Project root**: `/home/ksopyla/dev/MrCogito`
- **HuggingFace cache**: `/home/ksopyla/hf_home/`
- **Models and checkpoints output saved to**: /home/ksopyla/dev/MrCogito/Cache/Training
- **Training logs saved to**: /home/ksopyla/dev/MrCogito/Cache/logs
- **Evaluation reports saved to**: /home/ksopyla/dev/MrCogito/Cache/Evaluation_reports
- **wandb logs saved to**: /home/ksopyla/dev/MrCogito/wandb

## Running Training on Remote Servers
```bash
# SSH in, then:
cd ~/dev/MrCogito
git pull  # sync latest code

# Multi-GPU training
bash scripts/train_mlm_multigpu_perceiver.sh
bash scripts/train_recursive_mlm.sh
```

## Multi-GPU Key Details (CRITICAL)
- **Framework**: `accelerate` with DDP + NCCL backend
- **Critical bug**: Never use `.expand()` in model forward pass in distributed training â€” use `.repeat()` instead to avoid NCCL gradient synchronization deadlocks (see `docs/debugging/nccl_timeout_fix_2025-11-11.md`).
- Effective batch size = `PER_DEVICE_BATCH_SIZE * NUM_GPUS * GRADIENT_ACCUMULATION_STEPS`.

## Key Environment Variables
```bash
export HF_HOME="/home/ksopyla/hf_home/"
export HF_DATASETS_CACHE="/home/ksopyla/hf_home/datasets/"
export WANDB_API_KEY="..."                    # from .env file
export NCCL_TIMEOUT=3600                      # 1-hour timeout for multi-GPU
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
export OMP_NUM_THREADS=8
```