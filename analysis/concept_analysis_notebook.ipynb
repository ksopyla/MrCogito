{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Concept Encoder Analysis Notebook\n",
        "\n",
        "A comprehensive analysis toolkit for understanding what concepts learn in the ConceptEncoder architecture.\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook provides:\n",
        "1. **Concept Space Geometry** - Effective rank, isotropy, uniformity, collapse detection\n",
        "2. **Attention Pattern Analysis** - Concept-token attention visualization\n",
        "3. **Concept Specialization** - What tokens/patterns each concept captures\n",
        "4. **Publication-Quality Visualizations** - Figures for research papers\n",
        "\n",
        "### Research Background\n",
        "- VICReg (Bardes et al., 2021): Variance-Invariance-Covariance analysis\n",
        "- Perceiver IO (Jaegle et al., 2021): Cross-attention bottleneck analysis  \n",
        "- Probing Tasks (Miaschi et al., 2020): Linguistic property probing\n",
        "- Intrinsic Dimensionality (Aghajanyan et al., 2020): Effective dimensionality\n",
        "- T-REGS (Mordacq et al., 2025): Uniformity and collapse metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup paths and imports\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add project root to path\n",
        "project_root = os.path.dirname(os.path.dirname(os.path.abspath('.')))\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "    \n",
        "# Also add current working directory\n",
        "cwd = os.getcwd()\n",
        "if cwd not in sys.path:\n",
        "    sys.path.insert(0, cwd)\n",
        "    \n",
        "# Move up to project root if we're in analysis folder\n",
        "if os.path.basename(cwd) == 'analysis':\n",
        "    os.chdir('..')\n",
        "    \n",
        "print(f\"Working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set aesthetic defaults\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Publication quality settings\n",
        "plt.rcParams.update({\n",
        "    'font.size': 12,\n",
        "    'axes.labelsize': 14,\n",
        "    'axes.titlesize': 16,\n",
        "    'xtick.labelsize': 12,\n",
        "    'ytick.labelsize': 12,\n",
        "    'legend.fontsize': 12,\n",
        "    'figure.figsize': (10, 8),\n",
        "    'figure.dpi': 100,\n",
        "    'savefig.dpi': 300,\n",
        "    'savefig.bbox': 'tight',\n",
        "    'font.family': 'sans-serif'\n",
        "})\n",
        "\n",
        "print(\"‚úÖ Core imports complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional imports with fallbacks\n",
        "try:\n",
        "    from sklearn.decomposition import PCA\n",
        "    from sklearn.manifold import TSNE\n",
        "    from sklearn.cluster import KMeans\n",
        "    HAS_SKLEARN = True\n",
        "except ImportError:\n",
        "    HAS_SKLEARN = False\n",
        "    print(\"‚ö†Ô∏è sklearn not available - some analyses will be limited\")\n",
        "\n",
        "try:\n",
        "    import umap\n",
        "    HAS_UMAP = True\n",
        "except ImportError:\n",
        "    HAS_UMAP = False\n",
        "    print(\"‚ö†Ô∏è umap not available - using t-SNE/PCA as fallback\")\n",
        "\n",
        "print(f\"‚úÖ sklearn available: {HAS_SKLEARN}\")\n",
        "print(f\"‚úÖ UMAP available: {HAS_UMAP}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import ConceptEncoder modules\n",
        "from nn.concept_encoder import ConceptEncoder, ConceptEncoderConfig\n",
        "from nn.concept_encoder_perceiver import ConceptEncoderForMaskedLMPerceiver\n",
        "from nn.concept_encoder_weighted import ConceptEncoderForMaskedLMWeighted\n",
        "\n",
        "# Import analysis toolkit\n",
        "from analysis.concept_analysis import (\n",
        "    compute_concept_geometry_metrics,\n",
        "    ConceptAttentionExtractor,\n",
        "    ConceptSpecializationAnalyzer,\n",
        "    ConceptVisualizer,\n",
        "    ConceptAnalyzer,\n",
        "    ConceptMetricsCallback\n",
        ")\n",
        "\n",
        "print(\"‚úÖ ConceptEncoder modules loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Model and Data\n",
        "\n",
        "Configure the model checkpoint and load data for analysis.\n",
        "\n",
        "**Important:** Update `MODEL_PATH` to point to your trained model checkpoint!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION - UPDATE THESE FOR YOUR MODEL\n",
        "# ============================================================\n",
        "MODEL_PATH = \"./Cache/Training/YOUR_MODEL_CHECKPOINT\"  # <-- UPDATE THIS!\n",
        "MODEL_TYPE = \"perceiver_mlm\"  # Options: \"perceiver_mlm\" or \"weighted_mlm\"\n",
        "TOKENIZER_NAME = \"bert-base-uncased\"\n",
        "OUTPUT_DIR = \"./Cache/Outputs/concept_analysis\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ Model path: {MODEL_PATH}\")\n",
        "print(f\"üîß Model type: {MODEL_TYPE}\")\n",
        "print(f\"üìÇ Output dir: {OUTPUT_DIR}\")\n",
        "\n",
        "# Check if model exists\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: Model path does not exist!\")\n",
        "    print(f\"   Please update MODEL_PATH to point to your trained checkpoint.\")\n",
        "    print(f\"   Example: './Cache/Training/perceiver_mlm_H512L4C128_20240115_120000'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)\n",
        "print(f\"‚úÖ Tokenizer loaded: {TOKENIZER_NAME}\")\n",
        "print(f\"   Vocab size: {tokenizer.vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
        "\n",
        "try:\n",
        "    if MODEL_TYPE == \"perceiver_mlm\":\n",
        "        model = ConceptEncoderForMaskedLMPerceiver.from_pretrained(MODEL_PATH)\n",
        "    elif MODEL_TYPE == \"weighted_mlm\":\n",
        "        model = ConceptEncoderForMaskedLMWeighted.from_pretrained(MODEL_PATH)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model type: {MODEL_TYPE}\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Print model config\n",
        "    config = model.config\n",
        "    print(f\"\\nüìä Model Configuration:\")\n",
        "    print(f\"   Vocab size: {config.vocab_size}\")\n",
        "    print(f\"   Hidden size: {config.hidden_size}\")\n",
        "    print(f\"   Num layers: {config.num_hidden_layers}\")\n",
        "    print(f\"   Num concepts: {config.concept_num}\")\n",
        "    print(f\"   Max sequence length: {config.max_sequence_length}\")\n",
        "\n",
        "    # Count parameters\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"\\n   Total parameters: {total_params:,} ({total_params/1e6:.1f}M)\")\n",
        "    \n",
        "    MODEL_LOADED = True\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Failed to load model: {e}\")\n",
        "    print(\"   Please update MODEL_PATH and re-run this cell.\")\n",
        "    MODEL_LOADED = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Concept Space Geometry Analysis\n",
        "\n",
        "Analyze the geometric properties of the learned concept space:\n",
        "\n",
        "| Metric | What It Measures | Healthy Range |\n",
        "|--------|------------------|---------------|\n",
        "| **Effective Rank** | How many dimensions are actually used | > 0.5 (normalized) |\n",
        "| **Isotropy** | Are all dimensions equally utilized? | > 0.01 |\n",
        "| **Uniformity** | Are concepts well-distributed on hypersphere? | < 0.1 |\n",
        "| **Max Similarity** | Collapse detection (too similar?) | < 0.5 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a sample dataset for analysis\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "if MODEL_LOADED:\n",
        "    print(\"üìö Loading WikiText dataset for analysis...\")\n",
        "    \n",
        "    # Use WikiText for analysis (clean, well-known text)\n",
        "    dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\", split=\"validation[:1000]\")\n",
        "    \n",
        "    # Filter and tokenize\n",
        "    def tokenize_function(examples):\n",
        "        texts = [t for t in examples['text'] if len(t.strip()) > 20]\n",
        "        if not texts:\n",
        "            return {'input_ids': [], 'attention_mask': []}\n",
        "        return tokenizer(texts, truncation=True, max_length=128, padding='max_length')\n",
        "    \n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset.column_names)\n",
        "    tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "    \n",
        "    dataloader = DataLoader(tokenized_dataset, batch_size=32, shuffle=False)\n",
        "    print(f\"‚úÖ Dataset loaded: {len(tokenized_dataset)} samples, {len(dataloader)} batches\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not loaded. Please load model first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect concept representations from multiple batches\n",
        "if MODEL_LOADED:\n",
        "    print(\"üîÑ Collecting concept representations...\")\n",
        "    \n",
        "    all_concepts = []\n",
        "    num_batches = min(10, len(dataloader))  # Limit for efficiency\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dataloader):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "            \n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            \n",
        "            # Get concept representations from encoder\n",
        "            if hasattr(model, 'encoder'):\n",
        "                concept_output = model.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            else:\n",
        "                concept_output = model.concept_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            \n",
        "            all_concepts.append(concept_output.cpu())\n",
        "    \n",
        "    # Combine all concepts: (total_samples, num_concepts, hidden_size)\n",
        "    concepts_tensor = torch.cat(all_concepts, dim=0)\n",
        "    print(f\"‚úÖ Collected concepts shape: {concepts_tensor.shape}\")\n",
        "    print(f\"   = {concepts_tensor.shape[0]} samples x {concepts_tensor.shape[1]} concepts x {concepts_tensor.shape[2]} hidden_dim\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute geometry metrics\n",
        "if MODEL_LOADED:\n",
        "    print(\"üìê Computing concept space geometry metrics...\\n\")\n",
        "    \n",
        "    metrics = compute_concept_geometry_metrics(concepts_tensor)\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"             CONCEPT SPACE GEOMETRY REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Effective Rank Analysis\n",
        "    print(f\"\\nüìä EFFECTIVE RANK (Information Utilization)\")\n",
        "    print(f\"   Raw effective rank: {metrics['effective_rank']:.2f} / {concepts_tensor.shape[2]} dims\")\n",
        "    print(f\"   Normalized (0-1):   {metrics['normalized_effective_rank']:.3f}\")\n",
        "    if metrics['normalized_effective_rank'] > 0.5:\n",
        "        print(f\"   ‚úÖ Good - Concepts use most of the embedding space\")\n",
        "    elif metrics['normalized_effective_rank'] > 0.2:\n",
        "        print(f\"   ‚ö†Ô∏è  Moderate - Some dimensions may be underutilized\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Low - Possible dimensional collapse!\")\n",
        "    \n",
        "    # Isotropy Analysis  \n",
        "    print(f\"\\nüîÆ ISOTROPY (Dimension Utilization Uniformity)\")\n",
        "    print(f\"   Isotropy score: {metrics['isotropy']:.4f}\")\n",
        "    if metrics['isotropy'] > 0.01:\n",
        "        print(f\"   ‚úÖ Good - Dimensions are utilized fairly uniformly\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  Low - Some dimensions dominate the representation\")\n",
        "    \n",
        "    # Uniformity Analysis\n",
        "    print(f\"\\nüéØ UNIFORMITY (Distribution on Hypersphere)\")\n",
        "    print(f\"   Uniformity loss: {metrics['uniformity']:.4f}\")\n",
        "    if metrics['uniformity'] < 0.1:\n",
        "        print(f\"   ‚úÖ Good - Concepts are well-distributed\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  High - Concepts may be clustered\")\n",
        "    \n",
        "    # Similarity Analysis (Collapse Detection)\n",
        "    print(f\"\\nüîç SIMILARITY ANALYSIS (Collapse Detection)\")\n",
        "    print(f\"   Mean pairwise similarity: {metrics['mean_similarity']:.4f}\")\n",
        "    print(f\"   Max pairwise similarity:  {metrics['max_similarity']:.4f}\")\n",
        "    print(f\"   Min pairwise similarity:  {metrics['min_similarity']:.4f}\")\n",
        "    \n",
        "    if metrics['max_similarity'] > 0.9:\n",
        "        print(f\"   ‚ùå CRITICAL: Some concepts are nearly identical (collapse!)\")\n",
        "    elif metrics['max_similarity'] > 0.5:\n",
        "        print(f\"   ‚ö†Ô∏è  Some concepts are highly similar\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ Good diversity between concepts\")\n",
        "    \n",
        "    # Variance Analysis\n",
        "    print(f\"\\nüìà VARIANCE ANALYSIS\")\n",
        "    print(f\"   Mean variance: {metrics['mean_variance']:.4f}\")\n",
        "    print(f\"   Variance std:  {metrics['var_std']:.4f}\")\n",
        "    \n",
        "    # Norm Statistics\n",
        "    print(f\"\\nüìè NORM STATISTICS\")\n",
        "    print(f\"   Mean norm: {metrics['mean_norm']:.4f}\")\n",
        "    print(f\"   Norm std:  {metrics['norm_std']:.4f}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Publication-Quality Visualizations\n",
        "\n",
        "Generate figures suitable for a research paper:\n",
        "\n",
        "1. **Concept Similarity Matrix** - Pairwise cosine similarity heatmap\n",
        "2. **Singular Value Spectrum** - Shows dimensionality usage (effective rank)\n",
        "3. **2D Projections** - PCA/t-SNE/UMAP visualizations of concept space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.1 Concept Similarity Matrix\n",
        "if MODEL_LOADED:\n",
        "    visualizer = ConceptVisualizer(save_dir=OUTPUT_DIR)\n",
        "    \n",
        "    # Average concepts across samples to get concept prototypes\n",
        "    concept_prototypes = concepts_tensor.mean(dim=0)  # (num_concepts, hidden_size)\n",
        "    \n",
        "    fig = visualizer.plot_concept_similarity_matrix(\n",
        "        concept_prototypes, \n",
        "        title=\"Concept Pairwise Cosine Similarity\"\n",
        "    )\n",
        "    plt.show()\n",
        "    print(f\"üíæ Saved to: {OUTPUT_DIR}/concept_similarity_matrix.png\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.2 Singular Value Spectrum\n",
        "if MODEL_LOADED:\n",
        "    fig = visualizer.plot_svd_spectrum(\n",
        "        concept_prototypes,\n",
        "        title=\"Singular Value Spectrum of Concept Representations\"\n",
        "    )\n",
        "    plt.show()\n",
        "    print(f\"üíæ Saved to: {OUTPUT_DIR}/svd_spectrum.png\")\n",
        "    \n",
        "    # Interpretation\n",
        "    print(\"\\nüìä Interpretation:\")\n",
        "    print(\"   - Rapid decay = low effective dimensionality (few dominant directions)\")\n",
        "    print(\"   - Slow decay = high effective dimensionality (many useful directions)\")\n",
        "    print(\"   - Knee/elbow = boundary between significant and noise dimensions\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.3 2D Projections (PCA, t-SNE)\n",
        "if MODEL_LOADED and HAS_SKLEARN:\n",
        "    # Flatten concepts for projection: (num_samples * num_concepts, hidden_size)\n",
        "    flat_concepts = concepts_tensor.reshape(-1, concepts_tensor.shape[-1]).numpy()\n",
        "    \n",
        "    # Create labels for coloring (concept index)\n",
        "    n_samples, n_concepts, hidden_dim = concepts_tensor.shape\n",
        "    concept_labels = np.tile(np.arange(n_concepts), n_samples)\n",
        "    \n",
        "    # PCA projection\n",
        "    fig = visualizer.plot_2d_projection(\n",
        "        flat_concepts,\n",
        "        labels=concept_labels,\n",
        "        method='pca',\n",
        "        title=\"PCA Projection of Concept Space\"\n",
        "    )\n",
        "    plt.show()\n",
        "    print(f\"üíæ Saved to: {OUTPUT_DIR}/pca_projection.png\")\n",
        "    \n",
        "    # t-SNE projection (on subset for efficiency)\n",
        "    subset_size = min(500 * n_concepts, len(flat_concepts))\n",
        "    indices = np.random.choice(len(flat_concepts), subset_size, replace=False)\n",
        "    \n",
        "    fig = visualizer.plot_2d_projection(\n",
        "        flat_concepts[indices],\n",
        "        labels=concept_labels[indices],\n",
        "        method='tsne',\n",
        "        title=\"t-SNE Projection of Concept Space\"\n",
        "    )\n",
        "    plt.show()\n",
        "    print(f\"üíæ Saved to: {OUTPUT_DIR}/tsne_projection.png\")\n",
        "else:\n",
        "    if not MODEL_LOADED:\n",
        "        print(\"‚ö†Ô∏è  Model not loaded.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  sklearn required for 2D projections.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Summary Report\n",
        "\n",
        "Generate a comprehensive summary of the analysis results for documentation and papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate summary report\n",
        "if MODEL_LOADED:\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    report = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"model_path\": MODEL_PATH,\n",
        "        \"model_type\": MODEL_TYPE,\n",
        "        \"model_config\": {\n",
        "            \"vocab_size\": config.vocab_size,\n",
        "            \"hidden_size\": config.hidden_size,\n",
        "            \"num_layers\": config.num_hidden_layers,\n",
        "            \"num_concepts\": config.concept_num,\n",
        "            \"max_sequence_length\": config.max_sequence_length\n",
        "        },\n",
        "        \"geometry_metrics\": {k: float(v) if isinstance(v, (float, np.floating)) else v \n",
        "                            for k, v in metrics.items()},\n",
        "        \"samples_analyzed\": concepts_tensor.shape[0]\n",
        "    }\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"=\" * 70)\n",
        "    print(\"                    CONCEPT ENCODER ANALYSIS SUMMARY\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nüìÖ Timestamp: {report['timestamp']}\")\n",
        "    print(f\"üìÅ Model: {MODEL_PATH}\")\n",
        "    print(f\"\\nüîß Configuration:\")\n",
        "    for k, v in report['model_config'].items():\n",
        "        print(f\"   {k}: {v}\")\n",
        "    \n",
        "    print(f\"\\nüìä Key Metrics:\")\n",
        "    print(f\"   Effective Rank (normalized): {metrics['normalized_effective_rank']:.3f}\")\n",
        "    print(f\"   Isotropy: {metrics['isotropy']:.4f}\")\n",
        "    print(f\"   Uniformity: {metrics['uniformity']:.4f}\")\n",
        "    print(f\"   Max Similarity: {metrics['max_similarity']:.4f}\")\n",
        "    \n",
        "    # Health Assessment\n",
        "    print(f\"\\nüè• Health Assessment:\")\n",
        "    issues = []\n",
        "    if metrics['normalized_effective_rank'] < 0.3:\n",
        "        issues.append(\"Low effective rank - possible dimensional collapse\")\n",
        "    if metrics['max_similarity'] > 0.7:\n",
        "        issues.append(\"High concept similarity - concepts may not be diverse\")\n",
        "    if metrics['uniformity'] > 0.5:\n",
        "        issues.append(\"High uniformity loss - concepts clustered\")\n",
        "    \n",
        "    if not issues:\n",
        "        print(\"   ‚úÖ Model appears healthy!\")\n",
        "    else:\n",
        "        for issue in issues:\n",
        "            print(f\"   ‚ö†Ô∏è  {issue}\")\n",
        "    \n",
        "    # Save report\n",
        "    report_path = os.path.join(OUTPUT_DIR, \"analysis_report.json\")\n",
        "    with open(report_path, 'w') as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "    print(f\"\\nüíæ Report saved to: {report_path}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Model not loaded.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
